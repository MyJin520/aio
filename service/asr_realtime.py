import collections

import logging
import os
import queue
import sys
import threading
import time

from typing import Dict, List, Optional, Tuple, Any

import numpy as np
from funasr import AutoModel

# æ–°å¢éŸ³é¢‘å¤„ç†ä¾èµ–
from pydub import AudioSegment

from config.asr_config import ASRConfig
from utlis.audio_helpers import list_audio_devices, start_audio_stream
from utlis.logger import get_logger
from utlis.sse_helpers import clear_sse_queue, send_sse_data


class RealTimeASR:
    def __init__(self, config: ASRConfig, logger: logging.Logger):
        self.config = config
        self.logger = logger
        self.audio_logger = get_logger("audio")
        self.model_logger = get_logger("model")
        self.recognition_logger = get_logger("recognition")

        # ç¦ç”¨ç¬¬ä¸‰æ–¹åº“å†—ä½™è¾“å‡º
        os.environ["TQDM_DISABLE"] = "1"
        os.environ["FUNASR_VERBOSE"] = "0"

        # çŠ¶æ€å˜é‡åˆå§‹åŒ–
        self.chunk_size_samples = int(config.sample_rate * config.chunk_duration_ms / 1000)
        self.audio_queue = queue.Queue()
        self.stop_event = threading.Event()  # å…¨å±€åœæ­¢ä¿¡å·
        self.sse_queue = queue.Queue(maxsize=config.sse_queue_maxsize)

        # è¯†åˆ«çŠ¶æ€
        self.recording_active = False  # æ˜¯å¦æ­£åœ¨è¯†åˆ«
        self.listen_mode = False  # æ˜¯å¦ä¸ºListenæ¨¡å¼
        self.text_buffer = collections.deque(maxlen=3)  # å…³é”®è¯æ£€æµ‹ç¼“å†²åŒº
        self.current_text = ""  # å½“å‰è¯†åˆ«æ–‡æœ¬
        self.final_results: List[str] = []  # æ™®é€šæ¨¡å¼ç»“æœ
        self.listen_results: List[str] = []  # Listenæ¨¡å¼ç»“æœ

        # é™éŸ³æ£€æµ‹çŠ¶æ€
        self.last_voice_time = time.time()
        self.waiting_for_silence = False
        self.silence_timeout_ended = False

        # æ¨¡å‹ä¸ç¼“å­˜
        self.model: Optional[AutoModel] = None
        self.model_cache: Dict[str, Any] = {}
        self.audio_stream: Optional[Any] = None

        # æ”¶é›†éŸ³é¢‘ç‰‡æ®µ
        self.audio_fragments = []  # æ”¶é›†è¯†åˆ«è¿‡ç¨‹ä¸­çš„éŸ³é¢‘ç‰‡æ®µ
        self.audio_sample_rate = config.sample_rate  # é‡‡æ ·ç‡
        self.audio_channels = 1  # å•å£°é“
        self.audio_sample_width = 2  # 16ä½éŸ³é¢‘ï¼ˆ2å­—èŠ‚/é‡‡æ ·ç‚¹ï¼‰
        self.audio_output_path = "tmp.mp3"  # è¾“å‡ºMP3æ–‡ä»¶è·¯å¾„

        # æ‰“å°é…ç½®ä¿¡æ¯
        self._log_config()

    def _log_config(self) -> None:
        """æ‰“å°åˆå§‹åŒ–é…ç½®"""
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“‹ ASR æœåŠ¡åˆå§‹åŒ–é…ç½®")
        self.logger.info(f"æ¨¡å‹è·¯å¾„: {self.config.model_path} (ä»…ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œä¸è‡ªåŠ¨ä¸‹è½½)")
        self.logger.info(f"è§¦å‘å…³é”®è¯: å¼€å§‹='{self.config.start_keyword}', ç»“æŸ='{self.config.stop_keyword}'")
        self.logger.info(f"é™éŸ³æ£€æµ‹: é˜ˆå€¼={self.config.silence_threshold}, è¶…æ—¶={self.config.silence_timeout_seconds}s")
        self.logger.info(f"éŸ³é¢‘é…ç½®: {self.config.sample_rate}Hz / {self.config.chunk_duration_ms}ms/å—")
        self.logger.info(f"éŸ³é¢‘ä¿å­˜: è¯†åˆ«åœæ­¢åå°†ä¿å­˜ä¸º {self.audio_output_path}")
        self.logger.info("=" * 60)

    def _convert_numpy_audio_to_segment(self, audio_data: np.ndarray) -> AudioSegment:
        try:
            # å°†float32ï¼ˆ-1~1ï¼‰è½¬æ¢ä¸ºint16ï¼ˆ-32768~32767ï¼‰
            audio_int16 = (audio_data * 32767).astype(np.int16)
            # è½¬æ¢ä¸ºå­—èŠ‚æµ
            audio_bytes = audio_int16.tobytes()
            # åˆ›å»ºAudioSegmentå¯¹è±¡
            audio_segment = AudioSegment(
                data=audio_bytes,
                sample_width=self.audio_sample_width,
                frame_rate=self.audio_sample_rate,
                channels=self.audio_channels
            )
            return audio_segment
        except Exception as e:
            self.audio_logger.error(f"âŒ éŸ³é¢‘æ ¼å¼è½¬æ¢å¤±è´¥: {str(e)}")
            raise

    def _merge_audio_fragments(self) -> None:
        """
        åˆå¹¶æ”¶é›†çš„éŸ³é¢‘ç‰‡æ®µä¸ºMP3æ–‡ä»¶
        """
        if not self.audio_fragments:
            self.audio_logger.warning("âš ï¸ æ— éŸ³é¢‘ç‰‡æ®µå¯åˆå¹¶")
            return

        try:
            # åˆå¹¶æ‰€æœ‰éŸ³é¢‘ç‰‡æ®µ
            merged_audio = AudioSegment.empty()
            for fragment in self.audio_fragments:
                merged_audio += fragment

            original_dBFS = merged_audio.dBFS
            original_max_dBFS = merged_audio.max_dBFS
            self.audio_logger.info(f"ğŸ“Š åŸå§‹éŸ³é¢‘ç»Ÿè®¡: dBFS={original_dBFS:.1f}, max_dBFS={original_max_dBFS:.1f}")

            if original_dBFS < -40:  # å¦‚æœéŸ³é‡æä½
                volume_gain_db = 25  # å¤§å¹…æå‡25dB
                self.audio_logger.info(f"ğŸ“ˆ æ£€æµ‹åˆ°æä½éŸ³é‡ï¼Œåº”ç”¨å¤§å¹…å¢ç›Š: +{volume_gain_db}dB")
                merged_audio = merged_audio + volume_gain_db

                # æ ‡å‡†åŒ–åˆ°ç›®æ ‡éŸ³é‡
                target_dBFS = -16.0  # ç›®æ ‡éŸ³é‡çº§åˆ«
                current_dBFS = merged_audio.dBFS
                if current_dBFS < target_dBFS:
                    needed_gain = target_dBFS - current_dBFS
                    if needed_gain > 0:
                        self.audio_logger.info(f"ğŸ¯ è¿›ä¸€æ­¥æ ‡å‡†åŒ–å¢ç›Š: +{needed_gain:.1f}dB (ç›®æ ‡: {target_dBFS}dBFS)")
                        merged_audio = merged_audio + min(needed_gain, 15)  # é™åˆ¶æœ€å¤§å¢ç›Š15dBé¿å…å‰Šæ³¢
            else:
                volume_gain_db = 12  # å¸¸è§„æå‡12dB
                self.audio_logger.info(f"ğŸ“ˆ å¸¸è§„éŸ³é‡å¢ç›Š: +{volume_gain_db}dB")
                merged_audio = merged_audio + volume_gain_db
                merged_audio = merged_audio.normalize(headroom=1.0)  # æ ‡å‡†åŒ–ï¼Œä¿ç•™1dB headroom

            # é˜²æ­¢å‰Šæ³¢ä¿æŠ¤
            max_possible = merged_audio.max
            if max_possible >= 32767:  # 16ä½éŸ³é¢‘æœ€å¤§å€¼
                self.audio_logger.warning(f"âš ï¸ æ£€æµ‹åˆ°å‰Šæ³¢é£é™©! å½“å‰æœ€å¤§å€¼: {max_possible}")
                # é™ä½éŸ³é‡ç›´åˆ°ä¸å‰Šæ³¢
                while merged_audio.max >= 32767 and volume_gain_db > 0:
                    volume_gain_db -= 2
                    merged_audio = merged_audio - 2
                    self.audio_logger.warning(f"âš ï¸ é™ä½éŸ³é‡ä»¥é¿å…å‰Šæ³¢ï¼Œæ–°å¢ç›Š: {volume_gain_db}dB")

            # æœ€ç»ˆéŸ³é‡æ£€æŸ¥å’Œå¾®è°ƒ
            final_dBFS = merged_audio.dBFS
            final_max_dBFS = merged_audio.max_dBFS

            self.audio_logger.info(f"ğŸ“Š å¤„ç†åéŸ³é¢‘ç»Ÿè®¡: dBFS={final_dBFS:.1f}, max_dBFS={final_max_dBFS:.1f}")

            # å¦‚æœä»ç„¶å¤ªä½ï¼Œå†æ¬¡å°è¯•æå‡
            if final_dBFS < -30:
                additional_gain = min(10, -30 - final_dBFS)  # æœ€å¤šå†æå‡10dB
                if additional_gain > 0:
                    self.audio_logger.info(f"ğŸ“ˆ äºŒæ¬¡å¢ç›Š: +{additional_gain:.1f}dB")
                    merged_audio = merged_audio + additional_gain
                    final_dBFS = merged_audio.dBFS
                    final_max_dBFS = merged_audio.max_dBFS
                    self.audio_logger.info(f"ğŸ“Š äºŒæ¬¡å¤„ç†å: dBFS={final_dBFS:.1f}, max_dBFS={final_max_dBFS:.1f}")
            merged_audio.export(
                self.audio_output_path,
                format="mp3",
                bitrate="192k",  # æé«˜æ¯”ç‰¹ç‡
                parameters=["-q:a", "0"]  # æœ€é«˜è´¨é‡
            )

            final_duration = len(merged_audio) / 1000
            self.audio_logger.info(f"âœ… éŸ³é¢‘å·²ä¿å­˜ä¸º: {self.audio_output_path} (æ—¶é•¿: {final_duration:.2f}s)")
            self.audio_logger.info(f"ğŸ¯ æœ€ç»ˆéŸ³é‡: {final_dBFS:.1f}dBFS (ç›®æ ‡èŒƒå›´: -25 ~ -10 dBFS)")
            self.audio_logger.info(f"ğŸ”Š å³°å€¼éŸ³é‡: {final_max_dBFS:.1f}dBFS (åº” < 0dBFS é¿å…å‰Šæ³¢)")
            if final_dBFS < -25:
                self.audio_logger.warning("âš ï¸ éŸ³é‡ä»ç„¶åä½ï¼Œå»ºè®®æ£€æŸ¥éŸ³é¢‘é‡‡é›†è®¾å¤‡å¢ç›Šè®¾ç½®")
            if final_max_dBFS >= -1.0:
                self.audio_logger.warning("âš ï¸ å³°å€¼éŸ³é‡æ¥è¿‘0dBFSï¼Œå¯èƒ½å­˜åœ¨è½»å¾®å‰Šæ³¢")

        except Exception as e:
            self.audio_logger.error(f"âŒ éŸ³é¢‘åˆå¹¶å¤±è´¥: {str(e)}")
            import traceback
            self.audio_logger.error(traceback.format_exc())
        finally:
            self.audio_fragments.clear()
            self.audio_logger.info("ğŸ”„ éŸ³é¢‘ç‰‡æ®µç¼“å­˜å·²æ¸…ç©º")

    # æ¨¡å‹ç®¡ç†
    def _validate_model_path(self, model_path: str) -> bool:
        """éªŒè¯æ¨¡å‹è·¯å¾„æœ‰æ•ˆæ€§"""
        if not model_path:
            self.model_logger.error("âŒ æ¨¡å‹è·¯å¾„æœªé…ç½®ï¼ˆmodel_pathä¸ºç©ºï¼‰")
            return False

        if not os.path.exists(model_path):
            self.model_logger.error(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            return False

        # æ£€æŸ¥æ˜¯å¦ä¸ºç›®å½•
        if not os.path.isdir(model_path):
            self.model_logger.error(f"âŒ æ¨¡å‹è·¯å¾„ä¸æ˜¯ç›®å½•: {model_path}")
            return False

        missing = [f for f in self.config.required_model_files if not os.path.exists(os.path.join(model_path, f))]
        if missing:
            self.model_logger.error(f"âŒ æ¨¡å‹è·¯å¾„ç¼ºå¤±å¿…è¦æ–‡ä»¶: {missing}")
            return False

        self.model_logger.info(f"âœ… æ¨¡å‹è·¯å¾„éªŒè¯æˆåŠŸ: {model_path}")
        return True

    def load_model(self) -> None:
        """åŠ è½½æ¨¡å‹ï¼ˆä»…ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼Œä¸ä¸‹è½½ï¼‰"""
        # éªŒè¯æ¨¡å‹è·¯å¾„
        if not self._validate_model_path(self.config.model_path):
            error_msg = f"âŒ æ¨¡å‹è·¯å¾„éªŒè¯å¤±è´¥: {self.config.model_path}ï¼Œæ— æ³•åŠ è½½æ¨¡å‹"
            self.model_logger.error(error_msg)
            raise RuntimeError(error_msg)

        # æ¨¡å‹åŠ è½½é‡è¯•é€»è¾‘ï¼ˆä»…æœ¬åœ°åŠ è½½ç­–ç•¥ï¼‰
        load_strategies = [
            {"model": self.config.model_path, "hub": "local"},
            {"model": self.config.model_path}
        ]

        for idx, strategy in enumerate(load_strategies):
            try:
                self.model_logger.info(f"ğŸ” å°è¯•åŠ è½½æ¨¡å‹ (ç­–ç•¥{idx + 1}): {strategy}")
                self.model = AutoModel(
                    **strategy,
                    disable_pbar=True,
                    disable_update=True
                )
                self.model_logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
                return
            except Exception as e:
                self.model_logger.warning(f"âš ï¸ ç­–ç•¥{idx + 1}åŠ è½½å¤±è´¥: {str(e)[:100]}")

        error_msg = f"âŒ æ‰€æœ‰æœ¬åœ°æ¨¡å‹åŠ è½½ç­–ç•¥å‡å¤±è´¥ï¼Œè¯·æ£€æŸ¥æ¨¡å‹è·¯å¾„æˆ–æ¨¡å‹æ–‡ä»¶å®Œæ•´æ€§: {self.config.model_path}"
        self.model_logger.error(error_msg)
        raise RuntimeError(error_msg)

    # éŸ³é¢‘å¤„ç†
    def _audio_callback(self, indata: np.ndarray, frames, time, status) -> None:
        """éŸ³é¢‘é‡‡é›†å›è°ƒ"""
        if status:
            self.audio_logger.warning(f"âš ï¸ éŸ³é¢‘çŠ¶æ€å¼‚å¸¸: {status}")
        try:
            # æå–å•å£°é“éŸ³é¢‘æ•°æ®
            audio_data = indata[:, 0].copy().astype(np.float32)
            self.audio_queue.put(audio_data)
            if self.recording_active:
                audio_segment = self._convert_numpy_audio_to_segment(audio_data)
                self.audio_fragments.append(audio_segment)

        except Exception as e:
            self.audio_logger.error(f"âŒ éŸ³é¢‘å›è°ƒé”™è¯¯: {str(e)}")

    def _is_silent(self, audio_chunk: np.ndarray) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºé™éŸ³"""
        energy = np.sqrt(np.mean(audio_chunk ** 2))
        if energy < self.config.silence_threshold:
            self.audio_logger.debug(f"ğŸ”‡ æ£€æµ‹åˆ°é™éŸ³å—ï¼Œèƒ½é‡: {energy:.6f}")
            return True
        return False

    # è¯†åˆ«
    def _process_audio_chunk(self, audio_chunk: np.ndarray, is_final: bool = False) -> str:
        """å¤„ç†å•å—éŸ³é¢‘è¯†åˆ«"""
        if self.model is None:
            return ""

        try:
            # é‡å®šå‘stdouté¿å…ç¬¬ä¸‰æ–¹åº“è¾“å‡º
            with open(os.devnull, 'w') as devnull:
                old_stdout = sys.stdout
                sys.stdout = devnull
                try:
                    self.recognition_logger.debug(f"ğŸ¤ å¤„ç†éŸ³é¢‘å—ï¼Œé•¿åº¦: {len(audio_chunk)}ï¼Œis_final: {is_final}")
                    res = self.model.generate(
                        input=audio_chunk,
                        cache=self.model_cache,
                        is_final=is_final,
                        chunk_size=self.config.chunk_size,
                        encoder_chunk_look_back=self.config.encoder_chunk_look_back,
                        decoder_chunk_look_back=self.config.decoder_chunk_look_back
                    )
                finally:
                    sys.stdout = old_stdout

            if not res or len(res) == 0 or 'text' not in res[0]:
                self.recognition_logger.debug("ğŸ“­ éŸ³é¢‘è¯†åˆ«è¿”å›ç©ºç»“æœ")
                return ""

            text = res[0]['text'].strip()
            if text:
                self.recognition_logger.debug(f"ğŸ¯ è¯†åˆ«ç»“æœ: '{text}'")
            return text
        except Exception as e:
            self.recognition_logger.error(f"âŒ éŸ³é¢‘è¯†åˆ«é”™è¯¯: {str(e)}")
            return ""

    def _check_keywords(self) -> Tuple[bool, bool]:
        """æ£€æŸ¥ç¼“å†²åŒºä¸­çš„å…³é”®è¯"""
        buffer_text = "".join(self.text_buffer)
        start_detected = self.config.start_keyword in buffer_text
        stop_detected = self.config.stop_keyword in buffer_text

        if start_detected:
            self.recognition_logger.info(f"ğŸ”‘ æ£€æµ‹åˆ°å¼€å§‹å…³é”®è¯: '{self.config.start_keyword}'ï¼Œç¼“å†²åŒº: '{buffer_text}'")
        if stop_detected:
            self.recognition_logger.info(f"ğŸ”‘ æ£€æµ‹åˆ°ç»“æŸå…³é”®è¯: '{self.config.stop_keyword}'ï¼Œç¼“å†²åŒº: '{buffer_text}'")

        return start_detected, stop_detected

    def _reset_recognition_state(self) -> None:
        """é‡ç½®è¯†åˆ«çŠ¶æ€"""
        self.model_cache.clear()
        self.text_buffer.clear()
        self.current_text = ""
        clear_sse_queue(self.sse_queue, self.logger)
        self.last_voice_time = time.time()
        self.waiting_for_silence = False
        self.silence_timeout_ended = False
        # é‡ç½®æ—¶æ¸…ç©ºéŸ³é¢‘ç‰‡æ®µï¼ˆé¿å…æ®‹ç•™ï¼‰
        self.audio_fragments.clear()
        self.recognition_logger.info("ğŸ”„ è¯†åˆ«çŠ¶æ€å·²é‡ç½®")

    # ------------------------ è¯†åˆ«çº¿ç¨‹ ------------------------
    def _recognition_worker(self) -> None:
        """è¯†åˆ«å·¥ä½œçº¿ç¨‹"""
        if self.model is None:
            self.load_model()

        audio_buffer = np.array([], dtype=np.float32)
        self.recognition_logger.info("ğŸ¤ å®æ—¶è¯­éŸ³è¯†åˆ«çº¿ç¨‹å·²å¯åŠ¨")

        try:
            while not self.stop_event.is_set():
                try:
                    # è·å–éŸ³é¢‘å—ï¼ˆè¶…æ—¶é¿å…æ­»ç­‰ï¼‰
                    audio_chunk = self.audio_queue.get(timeout=0.5)

                    # 1. é™éŸ³è¶…æ—¶å¤„ç†
                    if self.recording_active:
                        self._handle_silence_timeout(audio_chunk)
                        if self.silence_timeout_ended:
                            self._reset_recognition_state()
                            audio_buffer = np.array([], dtype=np.float32)
                            continue

                    # 2. éŸ³é¢‘ç¼“å†²åŒºå¤„ç†
                    audio_buffer = np.concatenate([audio_buffer, audio_chunk])
                    while len(audio_buffer) >= self.chunk_size_samples:
                        # æå–å¾…å¤„ç†éŸ³é¢‘å—
                        process_chunk = audio_buffer[:self.chunk_size_samples]
                        audio_buffer = audio_buffer[self.chunk_size_samples:]

                        # 3. éŸ³é¢‘è¯†åˆ«
                        recognized_text = self._process_audio_chunk(process_chunk)
                        if not recognized_text:
                            continue

                        # 4. å…³é”®è¯æ£€æµ‹
                        self.text_buffer.append(recognized_text)
                        start_detected, stop_detected = self._check_keywords()

                        # 5. çŠ¶æ€æ§åˆ¶ï¼ˆå¼€å§‹/åœæ­¢/Listenæ¨¡å¼ï¼‰
                        self._handle_recognition_state(start_detected, stop_detected, recognized_text)

                        # 6. å®æ—¶ç»“æœæ¨é€
                        if self.recording_active and recognized_text != self.current_text:
                            self.current_text = recognized_text
                            self._log_realtime_text(recognized_text)
                            send_sse_data(self.sse_queue, 'partial', recognized_text)

                except queue.Empty:
                    continue
                except Exception as e:
                    self.recognition_logger.error(f"âŒ è¯†åˆ«çº¿ç¨‹å¼‚å¸¸: {str(e)}")
                    continue

        finally:
            # å¤„ç†å‰©ä½™éŸ³é¢‘
            self._process_remaining_audio(audio_buffer)
            clear_sse_queue(self.sse_queue, self.logger)

    def _handle_silence_timeout(self, audio_chunk: np.ndarray) -> None:
        """å¤„ç†é™éŸ³è¶…æ—¶é€»è¾‘"""
        is_silent = self._is_silent(audio_chunk)

        if is_silent:
            if not self.waiting_for_silence:
                self.waiting_for_silence = True
                self.recognition_logger.info(f"â³ æ£€æµ‹åˆ°é™éŸ³ï¼Œ{self.config.silence_timeout_seconds}ç§’åè‡ªåŠ¨ç»“æŸ")
        else:
            self.last_voice_time = time.time()
            if self.waiting_for_silence:
                self.waiting_for_silence = False
                self.recognition_logger.info("ğŸ¤ æ£€æµ‹åˆ°è¯­éŸ³ï¼Œç»§ç»­è¯†åˆ«")

        # é™éŸ³è¶…æ—¶è§¦å‘
        if self.waiting_for_silence:
            silence_duration = time.time() - self.last_voice_time
            if silence_duration > self.config.silence_timeout_seconds:
                self.recognition_logger.info(f"ğŸ”´ é™éŸ³è¶…æ—¶({silence_duration:.1f}s)ï¼Œåœæ­¢è¯†åˆ«")
                self.recording_active = False
                self.silence_timeout_ended = True

                # ä¿å­˜ç»“æœå¹¶æ¨é€
                if self.current_text:
                    target_results = self.listen_results if self.listen_mode else self.final_results
                    target_results.append(self.current_text)
                    send_sse_data(self.sse_queue, 'final', self.current_text)

                # é™éŸ³è¶…æ—¶åœæ­¢æ—¶åˆå¹¶éŸ³é¢‘
                self._merge_audio_fragments()

                # ç»Ÿä¸€å‘é€ListenBreakï¼Œå¢åŠ modeå­—æ®µåŒºåˆ†æ¨¡å¼
                mode = "listen" if self.listen_mode else "normal"
                send_sse_data(
                    self.sse_queue,
                    'ListenBreak',
                    f'{mode.capitalize()}æ¨¡å¼å› é™éŸ³è¶…æ—¶ç»“æŸ',
                    mode=mode,  # åŒºåˆ†æ™®é€š/listenæ¨¡å¼
                    reason='silence_timeout'  # æ ‡æ³¨ç»“æŸåŸå› 
                )

                self.recognition_logger.info(f"ğŸ”„ {'Listen' if self.listen_mode else 'æ™®é€š'}æ¨¡å¼å›åˆ°ç­‰å¾…çŠ¶æ€")

    def _handle_recognition_state(self, start_detected: bool, stop_detected: bool, text: str) -> None:
        """å¤„ç†è¯†åˆ«çŠ¶æ€åˆ‡æ¢ï¼ˆæ ¸å¿ƒä¼˜åŒ–ï¼šæ™®é€šæ¨¡å¼ç»“æŸä¹Ÿå‘é€ListenBreakï¼‰"""
        # Listenæ¨¡å¼å¯åŠ¨
        if self.listen_mode and not self.recording_active:
            self.recognition_logger.info("ğŸŸ¢ Listenæ¨¡å¼å¼€å§‹è¯†åˆ«")
            self.recording_active = True
            self._reset_recognition_state()
            return

        # æ™®é€šæ¨¡å¼å¼€å§‹
        if start_detected and not self.recording_active and not self.listen_mode:
            self.recognition_logger.info(f"ğŸŸ¢ æ£€æµ‹åˆ°å¼€å§‹å…³é”®è¯'{self.config.start_keyword}'ï¼Œå¼€å§‹è¯†åˆ«")
            self.recording_active = True
            self._reset_recognition_state()
            return

        # åœæ­¢è¯†åˆ«
        if stop_detected and self.recording_active:
            self.recognition_logger.info(f"ğŸ”´ æ£€æµ‹åˆ°ç»“æŸå…³é”®è¯'{self.config.stop_keyword}'ï¼Œåœæ­¢è¯†åˆ«")
            self.recording_active = False
            self.silence_timeout_ended = False

            # ä¿å­˜ç»“æœ
            if self.current_text:
                target_results = self.listen_results if self.listen_mode else self.final_results
                target_results.append(self.current_text)
                send_sse_data(self.sse_queue, 'final', self.current_text)

            # å…³é”®è¯åœæ­¢æ—¶ï¼Œåˆå¹¶éŸ³é¢‘
            self._merge_audio_fragments()

            # é‡ç½®çŠ¶æ€
            self._reset_recognition_state()

            # ç»Ÿä¸€å‘é€ListenBreakï¼ŒåŒºåˆ†æ¨¡å¼å’ŒåŸå› 
            if self.listen_mode:
                self.listen_mode = False
                send_sse_data(
                    self.sse_queue,
                    'ListenBreak',
                    'Listenæ¨¡å¼å› æ£€æµ‹åˆ°ç»“æŸå…³é”®è¯ç»“æŸ',
                    mode='listen',
                    reason='stop_keyword'
                )
                self.recognition_logger.info("ğŸ”„ Listenæ¨¡å¼å›åˆ°ç­‰å¾…çŠ¶æ€ï¼ˆå…³é”®è¯è§¦å‘ï¼‰")
            else:
                send_sse_data(
                    self.sse_queue,
                    'ListenBreak',
                    f'æ™®é€šæ¨¡å¼å› æ£€æµ‹åˆ°ç»“æŸå…³é”®è¯ç»“æŸ',
                    mode='normal',
                    reason='stop_keyword'
                )
                self.recognition_logger.info(f"ğŸ”„ æ™®é€šæ¨¡å¼ç­‰å¾…ä¸‹ä¸€ä¸ªå¼€å§‹å…³é”®è¯'{self.config.start_keyword}'")

    def _process_remaining_audio(self, audio_buffer: np.ndarray) -> None:
        """å¤„ç†å‰©ä½™éŸ³é¢‘"""
        if len(audio_buffer) == 0:
            return

        self.recognition_logger.info("â³ å¤„ç†å‰©ä½™éŸ³é¢‘...")
        # è¡¥é›¶åˆ°æœ€å°å—å¤§å°
        if len(audio_buffer) < self.chunk_size_samples:
            padding_length = self.chunk_size_samples - len(audio_buffer)
            audio_buffer = np.pad(audio_buffer, (0, padding_length))
            self.recognition_logger.debug(f"ğŸ“ éŸ³é¢‘è¡¥é›¶ {padding_length} ä¸ªé‡‡æ ·ç‚¹")

        # æœ€ç»ˆè¯†åˆ«
        text = self._process_audio_chunk(audio_buffer[:self.chunk_size_samples], is_final=True)
        if text:
            clean_text = text.replace(self.config.start_keyword, '').replace(self.config.stop_keyword, '').strip()
            target_results = self.listen_results if self.listen_mode else self.final_results
            target_results.append(text)

            self._log_realtime_text(f"å‰©ä½™éŸ³é¢‘è¯†åˆ«: {clean_text}")
            send_sse_data(self.sse_queue, 'partial', clean_text)

            mode = "Listen" if self.listen_mode else "æ™®é€š"
            self.recognition_logger.info(f"ğŸ”„ {mode}æ¨¡å¼å›åˆ°ç­‰å¾…çŠ¶æ€")

    def _log_realtime_text(self, text: str) -> None:
        """æ‰“å°å®æ—¶è¯†åˆ«æ–‡æœ¬"""
        clean_text = text.replace(self.config.start_keyword, '').replace(self.config.stop_keyword, '').strip()
        if clean_text:
            self.recognition_logger.info(f"[{time.strftime('%H:%M:%S')}] ğŸ”„ å®æ—¶è¯†åˆ«: {clean_text}")

    def start(self) -> None:
        """å¯åŠ¨ASRæœåŠ¡"""
        try:
            # åˆå§‹åŒ–éŸ³é¢‘è®¾å¤‡
            list_audio_devices(self.logger)

            # å¯åŠ¨è¯†åˆ«çº¿ç¨‹
            self.recognition_thread = threading.Thread(
                target=self._recognition_worker,
                daemon=True,
                name="ASR_Worker"
            )
            self.recognition_thread.start()

            # å¯åŠ¨éŸ³é¢‘æµ
            self.audio_stream = start_audio_stream(
                self.config,
                self.audio_queue,
                self._audio_callback,
                self.logger
            )

            # ç­‰å¾…åœæ­¢ä¿¡å·
            while not self.stop_event.is_set():
                time.sleep(0.1)

        except KeyboardInterrupt:
            self.logger.info("ğŸ›‘ æ£€æµ‹åˆ°ä¸­æ–­ä¿¡å·ï¼Œæ­£åœ¨åœæ­¢æœåŠ¡...")
            # ç¨‹åºä¸­æ–­æ—¶åˆå¹¶éŸ³é¢‘
            self._merge_audio_fragments()
        except Exception as e:
            self.logger.error(f"âŒ ASRæœåŠ¡å¯åŠ¨å¤±è´¥: {str(e)}")
            raise
        finally:
            self.cleanup()

    def start_listen_mode(self) -> None:
        """å¯åŠ¨Listenæ¨¡å¼"""
        if self.listen_mode:
            raise RuntimeError("å·²åœ¨Listenæ¨¡å¼ä¸­ï¼Œè¯·ç­‰å¾…å½“å‰ä¼šè¯ç»“æŸ")

        self.listen_mode = True
        self.listen_results.clear()
        self.recording_active = False
        self._reset_recognition_state()

        self.logger.info(
            f"ğŸŸ¢ Listenæ¨¡å¼å·²å¯åŠ¨ï¼Œè¯´å‡º'{self.config.stop_keyword}'æˆ–é™éŸ³{self.config.silence_timeout_seconds}ç§’ç»“æŸ")

    def get_listen_results(self) -> List[str]:
        """è·å–Listenæ¨¡å¼æ¸…ç†åçš„ç»“æœ"""
        return [
            r.replace(self.config.start_keyword, '').replace(self.config.stop_keyword, '').strip()
            for r in self.listen_results if r.strip()
        ]

    def cleanup(self) -> None:
        """æ¸…ç†èµ„æº"""
        self.logger.info("ğŸ§¹ å¼€å§‹æ¸…ç†èµ„æº...")

        # åœæ­¢äº‹ä»¶
        self.stop_event.set()

        # å…³é—­éŸ³é¢‘æµ
        if self.audio_stream:
            try:
                if hasattr(self.audio_stream, 'active') and self.audio_stream.active:
                    self.audio_stream.stop()
                self.audio_stream.close()
                self.logger.info("âœ… éŸ³é¢‘æµå·²å…³é—­")
            except Exception as e:
                self.logger.warning(f"âš ï¸ éŸ³é¢‘æµå…³é—­å¤±è´¥: {str(e)}")

        # é‡Šæ”¾æ¨¡å‹
        if self.model:
            try:
                del self.model
                self.logger.info("âœ… æ¨¡å‹èµ„æºå·²é‡Šæ”¾")
            except Exception as e:
                self.logger.warning(f"âš ï¸ æ¨¡å‹é‡Šæ”¾å¤±è´¥: {str(e)}")

        # æ¸…ç©ºé˜Ÿåˆ—
        clear_sse_queue(self.sse_queue, self.logger)

        # ç­‰å¾…çº¿ç¨‹ç»“æŸ
        if hasattr(self, 'recognition_thread'):
            self.recognition_thread.join(timeout=3.0)

        self.logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")
