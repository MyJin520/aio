import os
import sys
import collections
import threading
import queue
import time
import numpy as np
from typing import List, Optional, Dict, Any, Tuple
from funasr import AutoModel
from pydub import AudioSegment

from config.asr import ASRConfig
from services.base import BaseService
from utils.audio import AudioUtils
from utils.sse import SSEHelper


class ASRService(BaseService):
    """ASRè¯­éŸ³è¯†åˆ«æœåŠ¡"""

    def __init__(self, config: ASRConfig, logger):
        super().__init__(config, logger)

        # ç¦ç”¨ç¬¬ä¸‰æ–¹åº“å†—ä½™è¾“å‡º
        os.environ["TQDM_DISABLE"] = "1"
        os.environ["FUNASR_VERBOSE"] = "0"

        # çŠ¶æ€å˜é‡åˆå§‹åŒ–
        self.chunk_size_samples = int(config.sample_rate * config.chunk_duration_ms / 1000)
        self.audio_queue = queue.Queue()
        self.sse_queue = queue.Queue(maxsize=config.sse_queue_maxsize)

        # è¯†åˆ«çŠ¶æ€
        self.recording_active = False
        self.listen_mode = False
        self.text_buffer = collections.deque(maxlen=3)
        self.current_text = ""
        self.final_results: List[str] = []
        self.listen_results: List[str] = []

        # é™éŸ³æ£€æµ‹çŠ¶æ€
        self.last_voice_time = time.time()
        self.waiting_for_silence = False
        self.silence_timeout_ended = False

        # æ¨¡å‹ä¸éŸ³é¢‘æµ
        self.model: Optional[AutoModel] = None
        self.model_cache: Dict[str, Any] = {}
        self.audio_stream: Optional[Any] = None

        # éŸ³é¢‘æ”¶é›†
        self.audio_fragments = []
        self.recognition_thread: Optional[threading.Thread] = None

        # æ‰“å°é…ç½®ä¿¡æ¯
        self._log_config()

    def _log_config(self) -> None:
        """æ‰“å°åˆå§‹åŒ–é…ç½®"""
        self.logger.info("=" * 60)
        self.logger.info("ğŸ“‹ ASR æœåŠ¡åˆå§‹åŒ–é…ç½®")
        self.logger.info(f"è§¦å‘å…³é”®è¯: å¼€å§‹='{self.config.start_keyword}', ç»“æŸ='{self.config.stop_keyword}'")
        self.logger.info(f"é™éŸ³æ£€æµ‹: é˜ˆå€¼={self.config.silence_threshold}, è¶…æ—¶={self.config.silence_timeout_seconds}s")
        self.logger.info(f"éŸ³é¢‘é…ç½®: {self.config.sample_rate}Hz / {self.config.chunk_duration_ms}ms/å—")
        self.logger.info("=" * 60)

    def _audio_callback(self, indata: np.ndarray, frames, time, status) -> None:
        """éŸ³é¢‘é‡‡é›†å›è°ƒ"""
        if status:
            self.logger.warning(f"âš ï¸ éŸ³é¢‘çŠ¶æ€å¼‚å¸¸: {status}")
        try:
            audio_data = indata[:, 0].copy().astype(np.float32)
            self.audio_queue.put(audio_data)

            if self.recording_active:
                audio_segment = AudioUtils.convert_numpy_to_audio_segment(audio_data)
                self.audio_fragments.append(audio_segment)

        except Exception as e:
            self.logger.error(f"âŒ éŸ³é¢‘å›è°ƒé”™è¯¯: {str(e)}")

    def _validate_model_path(self, model_path: str) -> bool:
        """éªŒè¯æ¨¡å‹è·¯å¾„æœ‰æ•ˆæ€§"""
        if not model_path:
            self.logger.error("âŒ æ¨¡å‹è·¯å¾„æœªé…ç½®")
            return False

        if not os.path.exists(model_path):
            self.logger.error(f"âŒ æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}")
            return False

        if not os.path.isdir(model_path):
            self.logger.error(f"âŒ æ¨¡å‹è·¯å¾„ä¸æ˜¯ç›®å½•: {model_path}")
            return False

        missing = [f for f in self.config.required_model_files
                   if not os.path.exists(os.path.join(model_path, f))]
        if missing:
            self.logger.error(f"âŒ æ¨¡å‹è·¯å¾„ç¼ºå¤±å¿…è¦æ–‡ä»¶: {missing}")
            return False

        self.logger.info(f"âœ… æ¨¡å‹è·¯å¾„éªŒè¯æˆåŠŸ: {model_path}")
        return True

    def load_model(self) -> None:
        """åŠ è½½ASRæ¨¡å‹"""
        if self.config.model_path and self._validate_model_path(self.config.model_path):
            load_strategies = [
                {"model": self.config.model_path, "hub": "local"},
                {"model": self.config.model_path}
            ]

            for idx, strategy in enumerate(load_strategies):
                try:
                    self.logger.info(f"ğŸ” å°è¯•åŠ è½½æ¨¡å‹ (ç­–ç•¥{idx + 1}): {strategy}")
                    self.model = AutoModel(
                        **strategy,
                        disable_pbar=True,
                        disable_update=True
                    )
                    self.logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
                    return
                except Exception as e:
                    self.logger.warning(f"âš ï¸ ç­–ç•¥{idx + 1}åŠ è½½å¤±è´¥: {str(e)[:100]}")

            raise RuntimeError(f"æ‰€æœ‰æœ¬åœ°æ¨¡å‹åŠ è½½ç­–ç•¥å‡å¤±è´¥: {self.config.model_path}")
        else:
            raise RuntimeError("æœªé…ç½®æœ‰æ•ˆçš„æ¨¡å‹è·¯å¾„")

    def _process_audio_chunk(self, audio_chunk: np.ndarray, is_final: bool = False) -> str:
        """å¤„ç†éŸ³é¢‘å—è¯†åˆ«"""
        if self.model is None:
            return ""

        try:
            with open(os.devnull, 'w') as devnull:
                old_stdout = sys.stdout
                sys.stdout = devnull
                try:
                    res = self.model.generate(
                        input=audio_chunk,
                        cache=self.model_cache,
                        is_final=is_final,
                        chunk_size=self.config.chunk_size,
                        encoder_chunk_look_back=self.config.encoder_chunk_look_back,
                        decoder_chunk_look_back=self.config.decoder_chunk_look_back
                    )
                finally:
                    sys.stdout = old_stdout

            if not res or 'text' not in res[0]:
                return ""

            return res[0]['text'].strip()
        except Exception as e:
            self.logger.error(f"âŒ éŸ³é¢‘è¯†åˆ«é”™è¯¯: {str(e)}")
            return ""

    def _recognition_worker(self) -> None:
        """è¯†åˆ«å·¥ä½œçº¿ç¨‹"""
        if self.model is None:
            self.load_model()

        audio_buffer = np.array([], dtype=np.float32)
        self.logger.info("ğŸ¤ å®æ—¶è¯­éŸ³è¯†åˆ«çº¿ç¨‹å·²å¯åŠ¨")

        try:
            while not self.stop_event.is_set():
                try:
                    audio_chunk = self.audio_queue.get(timeout=0.5)

                    # é™éŸ³è¶…æ—¶å¤„ç†
                    if self.recording_active:
                        self._handle_silence_timeout(audio_chunk)
                        if self.silence_timeout_ended:
                            self._reset_recognition_state()
                            audio_buffer = np.array([], dtype=np.float32)
                            continue

                    # éŸ³é¢‘ç¼“å†²åŒºå¤„ç†
                    audio_buffer = np.concatenate([audio_buffer, audio_chunk])
                    while len(audio_buffer) >= self.chunk_size_samples:
                        process_chunk = audio_buffer[:self.chunk_size_samples]
                        audio_buffer = audio_buffer[self.chunk_size_samples:]

                        # éŸ³é¢‘è¯†åˆ«
                        recognized_text = self._process_audio_chunk(process_chunk)
                        if not recognized_text:
                            continue

                        # å…³é”®è¯æ£€æµ‹
                        self.text_buffer.append(recognized_text)
                        start_detected, stop_detected = self._check_keywords()

                        # çŠ¶æ€æ§åˆ¶
                        self._handle_recognition_state(start_detected, stop_detected, recognized_text)

                        # å®æ—¶ç»“æœæ¨é€
                        if self.recording_active and recognized_text != self.current_text:
                            self.current_text = recognized_text
                            self._log_realtime_text(recognized_text)
                            SSEHelper.send_sse_data(self.sse_queue, 'partial', recognized_text)

                except queue.Empty:
                    continue
                except Exception as e:
                    self.logger.error(f"âŒ è¯†åˆ«çº¿ç¨‹å¼‚å¸¸: {str(e)}")
                    continue

        finally:
            self._process_remaining_audio(audio_buffer)
            SSEHelper.clear_sse_queue(self.sse_queue, self.logger)

    def _is_silent(self, audio_chunk: np.ndarray) -> bool:
        """æ£€æµ‹æ˜¯å¦ä¸ºé™éŸ³"""
        return AudioUtils.is_silent(audio_chunk, self.config.silence_threshold)

    def _check_keywords(self) -> Tuple[bool, bool]:
        """æ£€æŸ¥æ–‡æœ¬ç¼“å†²åŒºä¸­æ˜¯å¦åŒ…å«å¼€å§‹æˆ–ç»“æŸå…³é”®è¯"""
        combined_text = "".join(self.text_buffer)
        start_detected = self.config.start_keyword in combined_text
        stop_detected = self.config.stop_keyword in combined_text
        return start_detected, stop_detected

    def _reset_recognition_state(self) -> None:
        """é‡ç½®è¯†åˆ«çŠ¶æ€"""
        self.recording_active = False
        self.listen_mode = False
        self.waiting_for_silence = False
        self.silence_timeout_ended = False
        self.current_text = ""
        self.text_buffer.clear()

        # å‘é€ç»“æŸäº‹ä»¶
        if self.final_results:
            SSEHelper.send_sse_data(self.sse_queue, 'final',
                                    " ".join(self.final_results))
            self.final_results.clear()

        # æ¸…ç©ºéŸ³é¢‘ç‰‡æ®µ
        if self.audio_fragments:
            self.audio_fragments.clear()

    def _handle_silence_timeout(self, audio_chunk: np.ndarray) -> None:
        """å¤„ç†é™éŸ³è¶…æ—¶"""
        if not self._is_silent(audio_chunk):
            self.last_voice_time = time.time()
            self.waiting_for_silence = False
        else:
            silence_duration = time.time() - self.last_voice_time
            if silence_duration > self.config.silence_timeout_seconds:
                if not self.waiting_for_silence:
                    self.waiting_for_silence = True
                    self.logger.info("ğŸ• æ£€æµ‹åˆ°é™éŸ³è¶…æ—¶ï¼Œç­‰å¾…ç»“æŸ...")
                else:
                    self.silence_timeout_ended = True
                    self.logger.info("â¹ï¸ é™éŸ³è¶…æ—¶ï¼Œè‡ªåŠ¨ç»“æŸè¯†åˆ«")

    def _handle_recognition_state(self, start_detected: bool, stop_detected: bool,
                                  recognized_text: str) -> None:
        """å¤„ç†è¯†åˆ«çŠ¶æ€å˜æ›´"""
        if start_detected and not self.recording_active:
            self.recording_active = True
            self.logger.info(f"â–¶ï¸ æ£€æµ‹åˆ°å¼€å§‹å…³é”®è¯: '{self.config.start_keyword}'ï¼Œå¼€å§‹å½•éŸ³")
            SSEHelper.send_sse_data(self.sse_queue, 'status', 'recording_started')

        elif stop_detected and self.recording_active:
            self.recording_active = False
            self.logger.info(f"â¹ï¸ æ£€æµ‹åˆ°ç»“æŸå…³é”®è¯: '{self.config.stop_keyword}'ï¼Œåœæ­¢å½•éŸ³")

            # å¤„ç†æœ€ç»ˆç»“æœ
            if recognized_text:
                self.final_results.append(recognized_text)
                if self.listen_mode:
                    self.listen_results.append(recognized_text)

            # å‘é€æœ€ç»ˆç»“æœ
            if self.final_results:
                final_text = " ".join(self.final_results)
                SSEHelper.send_sse_data(self.sse_queue, 'final', final_text)

                # ä¿å­˜éŸ³é¢‘
                if self.audio_fragments:
                    AudioUtils.merge_audio_segments(
                        self.audio_fragments,
                        self.config.audio_output_path,
                        logger=self.logger
                    )
                    self.audio_fragments.clear()

            # é‡ç½®çŠ¶æ€
            self._reset_recognition_state()

    def _process_remaining_audio(self, audio_buffer: np.ndarray) -> None:
        """å¤„ç†å‰©ä½™çš„éŸ³é¢‘ç¼“å†²åŒº"""
        if len(audio_buffer) > 0 and self.recording_active:
            # å¤„ç†å‰©ä½™çš„éŸ³é¢‘
            final_text = self._process_audio_chunk(audio_buffer, is_final=True)
            if final_text:
                self.final_results.append(final_text)
                final_result = " ".join(self.final_results)
                SSEHelper.send_sse_data(self.sse_queue, 'final', final_result)

                # ä¿å­˜éŸ³é¢‘
                if self.audio_fragments:
                    AudioUtils.merge_audio_segments(
                        self.audio_fragments,
                        self.config.audio_output_path,
                        logger=self.logger
                    )
                    self.audio_fragments.clear()

    def _log_realtime_text(self, text: str) -> None:
        """è®°å½•å®æ—¶è¯†åˆ«æ–‡æœ¬"""
        self.logger.info(f"ğŸ¤ å®æ—¶è¯†åˆ«: {text}")

    def start(self) -> None:
        """å¯åŠ¨ASRæœåŠ¡"""
        try:
            with self.thread_lock:
                if self.is_running:
                    self.logger.warning("æœåŠ¡å·²åœ¨è¿è¡Œä¸­")
                    return

                # åˆå§‹åŒ–éŸ³é¢‘è®¾å¤‡
                AudioUtils.list_audio_devices(self.logger)

                # å¯åŠ¨è¯†åˆ«çº¿ç¨‹
                self.recognition_thread = threading.Thread(
                    target=self._recognition_worker,
                    daemon=True,
                    name="ASR_Worker"
                )
                self.recognition_thread.start()

                # å¯åŠ¨éŸ³é¢‘æµ
                self.audio_stream = AudioUtils.start_audio_stream(
                    self.config.sample_rate,
                    self.config.chunk_duration_ms,
                    self._audio_callback,
                    self.logger
                )

                self.is_running = True
                self.logger.info("âœ… ASRæœåŠ¡å¯åŠ¨æˆåŠŸ")

        except Exception as e:
            self.logger.error(f"âŒ ASRæœåŠ¡å¯åŠ¨å¤±è´¥: {str(e)}")
            raise

    def stop(self) -> None:
        """åœæ­¢ASRæœåŠ¡"""
        with self.thread_lock:
            if not self.is_running:
                return

            self.stop_event.set()

            # å…³é—­éŸ³é¢‘æµ
            if self.audio_stream:
                try:
                    if hasattr(self.audio_stream, 'active') and self.audio_stream.active:
                        self.audio_stream.stop()
                    self.audio_stream.close()
                except Exception:
                    pass

            # é‡Šæ”¾æ¨¡å‹
            if self.model:
                try:
                    del self.model
                except Exception:
                    pass

            # ç­‰å¾…çº¿ç¨‹ç»“æŸ
            if self.recognition_thread:
                self.recognition_thread.join(timeout=3.0)

            # åˆå¹¶éŸ³é¢‘ç‰‡æ®µ
            if self.audio_fragments:
                AudioUtils.merge_audio_segments(
                    self.audio_fragments,
                    self.config.audio_output_path,
                    logger=self.logger
                )

            SSEHelper.clear_sse_queue(self.sse_queue, self.logger)
            self.is_running = False
            self.logger.info("âœ… ASRæœåŠ¡å·²åœæ­¢")

    def get_status(self) -> Dict[str, Any]:
        """è·å–æœåŠ¡çŠ¶æ€"""
        return {
            "status": "running" if self.is_running else "stopped",
            "service": "asr",
            "model_loaded": self.model is not None,
            "recording_active": self.recording_active,
            "listen_mode": self.listen_mode,
            "sse_queue_size": self.sse_queue.qsize()
        }